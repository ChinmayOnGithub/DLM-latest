input {
  beats {
    port => 5044
  }
}



# filter {
#   # Use a simple grok pattern or json codec depending on your log format.
#   # For generic NGINX logs, a basic grok pattern example:
#   grok {
#     match => { "message" => "%{COMMONAPACHELOG}" }
#   }
# }

# filter {
#   # Add filters to detect specific error patterns, e.g., 404 or 500 errors
#   if [status] == 404 {
#     mutate { add_tag => ["404_error"] }
#   }
#   if [status] >= 500 {
#     mutate { add_tag => ["server_error"] }
#   }
# }

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]  # Address for Elasticsearch
    index => "index"
    user => "elastic"
    password => "elk123"
  }
  stdout { codec => rubydebug }  # Output for debugging purposes
}


# filter {
#   # Parse log lines with a Grok pattern (customize based on your logs)
#   grok {
#     match => { "message" => "%{COMBINEDAPACHELOG}" }
#   }

#   # Extract timestamp from logs and convert it to @timestamp field
#   date {
#     match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]  # Adjust to your timestamp format
#     target => "@timestamp"
#     tag_on_failure => [ "_dateparsefailure" ]
#   }

#   # Add metadata from Kubernetes
#   if [kubernetes] {
#     mutate {
#       add_field => {
#         "pod_id" => "%{[kubernetes.pod.uid]}"
#         "namespace" => "%{[kubernetes.namespace]}"
#         "container_name" => "%{[kubernetes.container.name]}"
#       }
#     }
#   }

#   # Clean up log fields by removing unnecessary fields
#   mutate {
#     remove_field => [ "@version", "path", "host" ]
#   }

#   # Convert status field to integer if it exists
#   if [status] {
#     mutate {
#       convert => { "status" => "integer" }
#     }
#   }

#   # Drop empty messages or logs with no useful data
#   if [message] == "" or [message] == null {
#     drop { }
#   }
# }









# input {
#   beats {
#     port => 5044  # Port where Logstash listens for incoming Beats data (Filebeat)
#   }
# }

# filter {
#   if [source] =~ "nginx-" {
#     mutate {
#       add_field => { "service" => "nginx" }  # Add a field to identify the log source
#     }
#   } else if [source] =~ "mysql-" {
#     mutate {
#       add_field => { "service" => "mysql" }  # Add a field to identify the log source
#     }
#   }
# }

# output {
#   # if [service] == "nginx" {
#     elasticsearch {
#       hosts => ["localhost:9200"]  # Address and port for Elasticsearch
#       index => "mini-logs"  # Static index name for NGINX logs
#       user => "elastic"  # Username for Elasticsearch
#       password => "elk123"  # Updated password for Elasticsearch
    # }
  # } else if [service] == "mysql" {
  #   elasticsearch {
  #     hosts => ["localhost:9200"]  # Address and port for Elasticsearch
  #     index => "mysql-logs"  # Static index name for MySQL logs
  #     user => "elastic"  # Username for Elasticsearch
  #     password => "elk123"  # Updated password for Elasticsearch
  #   }
  # }

  # stdout { codec => rubydebug }  # Optional: Output to stdout for debugging purposes
# }


# input {
#   beats {
#     port => 5044  # The port where Filebeat sends logs
#   }
# }

# filter {
#   # Check for the 'pod' field from Filebeat
#   if [pod] {
#     # Use the 'pod' field for routing or processing
#     mutate {
#       add_field => { "source_pod" => "%{[pod]}" }
#     }

#     # Add a service field based on the pod name
#     if [pod] == "nginx-pod" {
#       mutate {
#         add_field => { "service" => "nginx" }
#       }
#     } else if [pod] == "mysql-pod" {
#       mutate {
#         add_field => { "service" => "mysql" }
#       }
#     }
#   }

#   # You can add more filters based on your log format and requirements
# }

# output {
#   # Output to Elasticsearch with authentication
#   if [service] == "nginx" {
#     elasticsearch {
#       hosts => ["localhost:9200"]  # Elasticsearch host
#       index => "nginx-logs-%{+YYYY.MM.dd}"  # Index for NGINX logs
#       user => "elastic"  # Username for Elasticsearch
#       password => "elk123"  # Password for Elasticsearch
#     }
#   } else if [service] == "mysql" {
#     elasticsearch {
#       hosts => ["localhost:9200"]  # Elasticsearch host
#       index => "mysql-logs-%{+YYYY.MM.dd}"  # Index for MySQL logs
#       user => "elastic"  # Username for Elasticsearch
#       password => "elk123"  # Password for Elasticsearch
#     }
#   }

#   # Optional: stdout for debugging
#   stdout {
#     codec => rubydebug  # Print events to console for debugging
#   }
# }
